{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b74faee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_FILE = \"./datasets/coco/annotations/instances_val2017.json\"\n",
    "DT_FILE = \"./runs/detect/train/predictions.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185a79a",
   "metadata": {},
   "source": [
    "## ORIG COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513e71fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=2.69s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=28.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=7.46s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
      "\n",
      "Memory Usage Profile:\n",
      "+-------------------------+----------------+----------+\n",
      "| Stage                   | Memory Usage   | Diff     |\n",
      "+=========================+================+==========+\n",
      "| 1. Initial              | 54.16 MB       | -        |\n",
      "+-------------------------+----------------+----------+\n",
      "| 2. Classes imported     | 54.16 MB       | +0.00    |\n",
      "+-------------------------+----------------+----------+\n",
      "| 3. Ground truth loaded  | 167.36 MB      | +113.20  |\n",
      "+-------------------------+----------------+----------+\n",
      "| 4. Predictions loaded   | 1081.80 MB     | +914.44  |\n",
      "+-------------------------+----------------+----------+\n",
      "| 5. Evaluator created    | 1081.95 MB     | +0.15    |\n",
      "+-------------------------+----------------+----------+\n",
      "| 6. Evaluation completed | 2258.05 MB     | +1176.10 |\n",
      "+-------------------------+----------------+----------+\n",
      "| 7. Results accumulated  | 2302.85 MB     | +44.80   |\n",
      "+-------------------------+----------------+----------+\n",
      "| 8. Summary generated    | 2303.00 MB     | +0.15    |\n",
      "+-------------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "!python memory_profile.py {GT_FILE} {DT_FILE} --coco-lib pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5281d37",
   "metadata": {},
   "source": [
    "## FASTER COCO EVAL (VERSION 1.6.7)\n",
    "\n",
    "```bash\n",
    "pip install \"faster-coco-eval==1.6.7\" --user -U\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad937d5",
   "metadata": {},
   "source": [
    "#### separate_eval == False (DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36aab86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_coco_eval __version__ = 1.6.7\n",
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Done (t=0.02s)\n",
      "Loading and preparing results...\n",
      "DONE (t=2.70s)\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished...\n",
      "DONE (t=4.94s).\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.644\n",
      "\n",
      "Memory Usage Profile:\n",
      "+-------------------------+----------------+---------+\n",
      "| Stage                   | Memory Usage   | Diff    |\n",
      "+=========================+================+=========+\n",
      "| 1. Initial              | 54.32 MB       | -       |\n",
      "+-------------------------+----------------+---------+\n",
      "| 2. Classes imported     | 54.32 MB       | +0.00   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 3. Ground truth loaded  | 168.30 MB      | +113.98 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 4. Predictions loaded   | 1082.68 MB     | +914.38 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 5. Evaluator created    | 1082.83 MB     | +0.15   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 6. Evaluation completed | 1797.67 MB     | +714.84 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 7. Results accumulated  | 1797.67 MB     | +0.00   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 8. Summary generated    | 1797.67 MB     | +0.00   |\n",
      "+-------------------------+----------------+---------+\n"
     ]
    }
   ],
   "source": [
    "!python memory_profile.py {GT_FILE} {DT_FILE} --coco-lib faster_coco_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf9c36",
   "metadata": {},
   "source": [
    "#### separate_eval == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48302730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_coco_eval __version__ = 1.6.7\n",
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Done (t=0.02s)\n",
      "Loading and preparing results...\n",
      "DONE (t=2.69s)\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished...\n",
      "DONE (t=4.57s).\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished...\n",
      "DONE (t=1.43s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.644\n",
      "\n",
      "Memory Usage Profile:\n",
      "+-------------------------+----------------+----------+\n",
      "| Stage                   | Memory Usage   | Diff     |\n",
      "+=========================+================+==========+\n",
      "| 1. Initial              | 54.09 MB       | -        |\n",
      "+-------------------------+----------------+----------+\n",
      "| 2. Classes imported     | 54.09 MB       | +0.00    |\n",
      "+-------------------------+----------------+----------+\n",
      "| 3. Ground truth loaded  | 168.07 MB      | +113.98  |\n",
      "+-------------------------+----------------+----------+\n",
      "| 4. Predictions loaded   | 1082.44 MB     | +914.37  |\n",
      "+-------------------------+----------------+----------+\n",
      "| 5. Evaluator created    | 1082.60 MB     | +0.16    |\n",
      "+-------------------------+----------------+----------+\n",
      "| 6. Evaluation completed | 2205.21 MB     | +1122.61 |\n",
      "+-------------------------+----------------+----------+\n",
      "| 7. Results accumulated  | 2447.88 MB     | +242.67  |\n",
      "+-------------------------+----------------+----------+\n",
      "| 8. Summary generated    | 2447.88 MB     | +0.00    |\n",
      "+-------------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "!python memory_profile.py {GT_FILE} {DT_FILE} --coco-lib faster_coco_eval --separate-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab35d7f5",
   "metadata": {},
   "source": [
    "## FASTER COCO EVAL (VERSION >= 1.7.0)\n",
    "\n",
    "```bash\n",
    "pip install \"faster-coco-eval>=1.7.0\" --user -U\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaace0d",
   "metadata": {},
   "source": [
    "#### separate_eval == False (DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d80f2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_coco_eval __version__ = 1.7.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Done (t=0.02s)\n",
      "Loading and preparing results...\n",
      "DONE (t=2.78s)\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished...\n",
      "DONE (t=4.36s).\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.644\n",
      "\n",
      "Memory Usage Profile:\n",
      "+-------------------------+----------------+---------+\n",
      "| Stage                   | Memory Usage   | Diff    |\n",
      "+=========================+================+=========+\n",
      "| 1. Initial              | 53.84 MB       | -       |\n",
      "+-------------------------+----------------+---------+\n",
      "| 2. Classes imported     | 53.84 MB       | +0.00   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 3. Ground truth loaded  | 167.78 MB      | +113.94 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 4. Predictions loaded   | 1082.17 MB     | +914.39 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 5. Evaluator created    | 1082.33 MB     | +0.16   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 6. Evaluation completed | 1645.67 MB     | +563.34 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 7. Results accumulated  | 1645.67 MB     | +0.00   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 8. Summary generated    | 1645.67 MB     | +0.00   |\n",
      "+-------------------------+----------------+---------+\n"
     ]
    }
   ],
   "source": [
    "!python memory_profile.py {GT_FILE} {DT_FILE} --coco-lib faster_coco_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863954b",
   "metadata": {},
   "source": [
    "#### separate_eval == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a64eb6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_coco_eval __version__ = 1.7.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Done (t=0.02s)\n",
      "Loading and preparing results...\n",
      "DONE (t=2.63s)\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished...\n",
      "DONE (t=3.75s).\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished...\n",
      "DONE (t=1.61s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.526\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.644\n",
      "\n",
      "Memory Usage Profile:\n",
      "+-------------------------+----------------+---------+\n",
      "| Stage                   | Memory Usage   | Diff    |\n",
      "+=========================+================+=========+\n",
      "| 1. Initial              | 54.15 MB       | -       |\n",
      "+-------------------------+----------------+---------+\n",
      "| 2. Classes imported     | 54.15 MB       | +0.00   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 3. Ground truth loaded  | 168.18 MB      | +114.03 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 4. Predictions loaded   | 1082.44 MB     | +914.26 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 5. Evaluator created    | 1082.60 MB     | +0.16   |\n",
      "+-------------------------+----------------+---------+\n",
      "| 6. Evaluation completed | 2068.26 MB     | +985.66 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 7. Results accumulated  | 2440.34 MB     | +372.08 |\n",
      "+-------------------------+----------------+---------+\n",
      "| 8. Summary generated    | 2440.34 MB     | +0.00   |\n",
      "+-------------------------+----------------+---------+\n"
     ]
    }
   ],
   "source": [
    "!python memory_profile.py {GT_FILE} {DT_FILE} --coco-lib faster_coco_eval --separate-eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
